# Chapter 6. Monitoring Distributed Systems

##  <Font color="red">Worrying About Your Tail (or, Instrumentation and Performance)</font>

あなたのしっぽについて悩んでいる

あるいは、<br>
Instrumentation = ハードウェアやソフトウェアの状態に関するデータを報告するために使用される機構<br>
Performance = パフォーマンス

この章では、しっぽをどう監視していくか？について記述
「しっぽ」とは、パフォーマンスのもっとも悪い値のことを指す

スクラッチで監視システムを構築する場合、いくつかの平均に基づいて設計するのが良いです

* latency(待ち時間)の平均
* ノードのCPU使用率の平均
* データベース負荷(fullness)の平均

だったり。
毎秒1,000件のリクエストを平均待ち時間：100ミリ秒で応答するWebサービスを実行する場合、そのうち1%は5秒かかるかもしれません。

この非常に遅い、しっぽとなるリクエストを区別する方法は
待ち時間によって分類されたリクエスト数をカウントします

* 0ms - 10ms
* 10ms - 30ms
* 30ms - 100ms
* 100ms - 300ms

のリクエスト数がどのくらいか？
そうすることでリクエストの分布を可視化することができます。

## <Font color="red">Choosing an Appropriate Resolution for Measurements</font>

計測のための適切な解決を選択する

この章では、システムを監視する中で色々な側面、aspectがあるが
それをどう適切に計測、解決するか？に記述

システムの異なった側面、aspectは、それぞれ粒度の異なるレベルで測定されるべきです

例えば
* 1分毎のCPUロードを監視した場合、（スパンが長すぎるので）瞬間的に高い（スパイクな）値を明確できない
* 一方、99.9%稼働、年間9時間未満をダウンタイムとするWebサービスで、1,2分間ごとに ステータス200 を応答するか監視することはあるが、1,2分間ごとにそのWebサービスのHDを監視することは（あまりなく）不要

どのように測定の粒度を構成するかを注意してください

CPU負荷の毎秒の測定値を収集することは、興味深いデータが得られるかもしれないが、頻繁にcollect, store, analyzeするので、非常にコストが高額になるかもしれない

もし、高度な解決を求めるが少しの遅延があっても良いのであれば、
取得したデータをいくつか内部的にサンプリングすれば、コストを削減することができる。

1. 毎秒のCPU使用率を記録
2. 5％の粒度のbucketsに、毎秒ごとのCPU使用率の値をインクリメントする。（サンプリング？）
3. 毎分のそれらの値を集計する

こうすることで、高コスト化を招くことなく、簡単にCPUのhotspotを観察することができる

## <Font color="red">As Simple as Possible, No Simpler</font>

できるだけシンプルに。単純ではない

この章では、監視システムのデータ収集と集約、アラートの構成は複雑化せず、よりシンプルに構成すべきである。と記述

監視システムであらゆる要件を積み上げると、非常に複雑な監視システムになるかもしれない。

例えば
* latencyがしきい値と異なる、パーセンタイル値が異なる、すべての種類の異なるメトリックスが発生した場合にアラートを発する

* 障害を検出し、考えられる要因を露出するためのExtra codeがある
* これらの考えられる要因のそれぞれについての関連するダッシュボード

潜在的な複雑さは終わることがない
すべてのソフトウェアシステムと同様、監視はとても複雑になり、それは壊れやすく、変更が複雑で、保守の負担があり、単純化に向けて監視システムを設計する必要がある

監視するために何を選択するかは、次のガイドラインに従ってください

* 実際の出来事をキャッチするルールは、可能な限り、シンプルで予測可能、かつ信頼できるものであるべき

* めったに実施されていないデータの収集、集約、およびアラート構成はできれば除去すべきです

* 収集したが、prebake？されたダッシュボートに露出していない、かつ任意の警告で使用されていないシグナルは、除去の候補です

Googleの経験では、アラートおよびダッシュボードとペアでmetricsの基本的な収集と集計は、スタンドアロンなシステムとして動作している

監視と複雑なシステムの色々な側面を組み合わせると、魅力的なことができるが、それは複雑で壊れやすく、多くの結果が混在することになる

ソフトウェアエンジニアリングと同様に、明確で、単純で、疎結合なシステムを維持することがより良い戦略

## <Font color="red">Tying These Principles Together</font>

ともにこれらの原則を型付けすること

この章では監視とアラートの原則について記述

この原則は広くGoogleのSREチーム内で承認し、続いている

監視とアラートのルールを作成するとき、次の質問をすると false positivesとpager burnoutを避けるのを助けることができる

false positives・・・誤った警告メッセージ
pager burnout・・・呼び出しによって疲労する

* このルールは、緊急、actionable（訴訟になる）、もしくはユーザの目に見えていて差し迫っている　以外は検出されない状態か？

* この警告は無視することができるか？いつ、そしてなぜこの警告を無視することができ、どのようにこのシナリオを回避することができるか？

* この警告は間違いなく、ユーザーがマイナスの影響を受けていることを示している？

* この警告に応答して行動を取ることはできますか？そのアクションが急務か、それとも朝まで待つことができるか？アクションは安全に自動化することができるか？長期的な修正、または単に短期的な回避策になるか？

* 他の人々はこのissueのために呼び出されるか？ それによって、呼び出しの少なくとも一つは不益か？

次に、page呼び出しの基本的な哲学を記述

* 呼び出しが鳴り出すたびに、切迫感を感じる必要がある
* すべての呼び出しは実用的であるべき
* 各呼び出しの応答は知性を要求すべきで、ロボット的な応答でよければ、それは呼び出しであるべきではない
* 呼び出しは、新規の問題か前に見られていないイベントであるべき

この哲学を満たしていないのであれば、一定の判定を分散させ、また判断を増幅させるので、監視によってトリガされべきではない

## <Font color="red">Monitoring for the Long Term</font>

長期的な監視

この章では、監視に関する２つのケーススタディを使用して
監視に関する決定は長期的な目標とすることが重要であることを記述

### Bigtable SRE: A Tale of Over-Alerting

Bigtable SRE：多すぎるアラートの逸話

Googleの内部インフラストラクチャはサービスレベルの目標（=SLO）が設定されていて、Bigtableのサービスも設定されていた

Bigtableやストレージ・スタックの問題で、リクエストのワースト5％は著しく遅いケースがあり、SLOに近づくと電子メールのアラートがトリガされ、SLOを超えたときはポケベルへの通知がトリガされた

この両方のアラートが大量にトリガされて、エンジニアが許容できない量の時間を費やしました。そして、実際にユーザーに影響を与えた問題を逃しました

状況を改善するために、
* Bigtableのパフォーマンスを向上させるための大きな努力をしながら、
一時的にSLO目標を下方修正（dialed back）しました
* 多くの時間を費やし、アラートを診断することが不可能だったので Eメールでのアラートを無効化しました

この戦略により、Bigtableの長期的な問題を修正するだけでなく、常に戦術的な問題を解決するのに十分な余裕を得られました

すべての時間帯で通知に追いついていなかったが、
この改善によりオンコールエンジニアが実際に作業を行うまでに至りました

### Gmail: Predictable, Scriptable Responses from Humans

Gmailは非常に初期の頃、Workqueueと呼ばれるプロセス管理システム上に構築されていました

Workqueueは比較的不透明なコードベースでバグがありました

Gmailの監視は、タスクが「de-scheduled」になったとき、アラートをトリガするよう、構築されました

エンジニアは他にたくさんのタスクを持っていてアラートの保守ができないので、さらにschedulerを「poke」 する（突っつく）ツールを構築しました。

チームの中で、アラートの検出からreschedulerを実行するまでの全ループを自動化すべきかどうか議論しました

これはあくまで回避策であり、本来のバグの修正を遅らせる心配があり
保守不可能な技術的負債になり得るという懸念があったからです

マネージャーとテクニカルリーダーがキーとなり、優先して、本当の長期的な修正を実行します

また、繰り返し、アルゴリズムがある通知は、警告を促す「red flag」であるべきで、そのような通知を自動化し回避することは、技術的負債をクリーンアップすることの自信に欠けている。

### The Long Run

この章では、前の章と同様、長期的な戦略が重要であることを記述

膨大な努力はガタガタのシステムの高可用性を成し遂げることができるが
この方法は短期的で燃え尽きる危険をはらんでいて、少数の英雄的メンバーに依存します

短期的なコントロールを減らすことは痛みを伴うが、これはシステムの長期安定性のために戦略的なトレードで、すべての通知を単独のイベントとして考えないことが重要です。

あと、
四半期ごとのレポートで、意思決定者が通知の負荷と彼らのチームの全体的な健全性に関して最新状態が保たれていることも重要です

## <Font color="red">Conclusion</font>

結論

Eメールの警告は、非常に制限された価値をもち、容易に、ノイズがはびこる傾向がある

代わりに、ダッシュボードを支持するべきです
ダッシュボードは進行中で露出前の問題を監視することができる

ダッシュボードはまた歴史の相互関係を分析するために、ログとともにペアで構成しても良い

長い目で見ると、on-call ローテーションの成功の実現と 徴候または差し迫っている本当の問題のアラートの選択を含む製品は 実際達成可能なゴールのために、あなたの目標を適応させ、 あなたの監視の急速診断をサポートすることを確実にします。

<hr>

# Chapter 7. The Evolution of Automation at Google

Googleの自動化の進化

SRE にとって、自動化は力を増強させる食べ物であるが万能薬ではない
不注意に自動化をすることは、それを解くのと同じくらい多くの問題が生じる

自動化の価値は、それが何をするかとその賢明なアプリケーションの両方から来ていて、自動化の価値と　どのような姿勢で進化してきたのか　の両方をこの章では説明します。

## <Font color="red">The Value of Automation</font>　　

自動化の価値

自動化の価値は何ですか？

### Consistency

一貫性

手動でのタスクだと、毎回同じ方法で実行されないが、自動化することで一貫性を確保できます
一貫性の欠如は、データの品質や信頼性の問題で、ミス、見落としの問題につながります

### A Platform

プラットフォーム

正しく設計された自動化システムは、拡張可能なプラットフォームを提供し
多くのシステムに適用され、または利益のために長く保たれます

また、プラットフォームは、誤りを一元化します。
バグがあれば、一度の修正で永遠に修正されます。
また、追加のタスクを実行するように拡張することもできます。

手動でのタスクと異なり、頻繁に連続的に、
また時として人間には不便な時間にも実行できます

その上、性能についてのメトリックスをエクスポートすることができ
以前は知らなかった手順についての詳細を発見することができる

### Faster Repairs

より早く修理する

自動化が定期的に正常に実行された場合、結果として失敗によるMTTR（平均復旧時間）が減少します。

また、問題の防止とそのあとのクリーンアップに費やす時間も必要ないので
開発者は他のタスクに費やすことができます。

MTTRが減少することで、その復旧に費やす時間とコストが減り、時間とお金の両方で、システムの総コストを下げるのに良い機会を持っています

### Faster Action

早いアクション

人間は通常、マシンほど速く反応できません

例えば、フェイルオーバーまたはトラフィック切り替えのたびに
人を必要とし、“Allow system to continue to run.” と呼ばれるボタンを都度おす状況は無意味です

Gooleは自動化の量が多く、それは管理可能な手動操作のしきい値を超えているため、自動化せずには生き残ることができませんでした。

### Time Saving

時間の節約

エンジニアは手動で行うタスクを自動化することに価値はあるのかと迷うことがありますが、自動化でいくつかのタスクをカプセル化すると、誰もがそのタスクを実行することができます

それによる時間の節約は誰もがに適用されます。

### WARNING

自動化しないことによる警告を記述？

もしエンジニアリング・プロセスと自動化されない解決策がある場合、
システムを維持するために人間のスタッフを持ち続ける必要があります。

それは、人間の血、汗、そして涙で、マシンを運用することになります

特別な効果が少ないマトリックス？で考え、そして、より多くのシステム管理者が去りました

## <Font color="red">The Value for Google SRE</font>

GoogleのSREのための価値

Googleは、自動化に向けた強いバイアスを持っています。

バイアス＝先入観・偏見・偏り・傾向

Googleの製品とサービスは地球にまたがる規模であり
マシンあるいはサービスを手作業で保持する時間はありません

本当に大規模なサービスのために、一貫性、迅速性、および信頼性の要因が
自動化を行う、行わないのトレードオフについての会話のほとんどを占めています

また、他の組織は、アクセス可能なAPIなしに重要な部分を担っているかもしれないが、ソースコードがないソフトウェアやその他の妨害があるようなシナリオはGoogleでは避けるようにしています

ベンダーから利用可能なAPIを入手できなかったとき、Googleではそのシステム用のAPIを構築していて、短期的かつ安価なソフトウェアを購入するよりも自身のソリューションを書くことを選んでます

それは、はるかに大きな長期的な利益を潜在に持つAPIにするためです。

自動化システムの管理の障害を克服するため、多くの時間を費やし、あえて自動化システムの管理自体を開発しました。

いかなるシステムのコードを利用できることは、 スタックの全部を支配することになるので、“own the product in production” 我々の任務が非常により簡単なことを意味します。

自動化することに心を傾けてはいるが、
すべての人が自動化を開発する傾きを持っていることはなく
現実ではアプローチの修正が必要としています

ただ、Googleのコンテキストの範囲内で、行動に加えることは成功していて、自身が作成、配置可能なプラットフォームを作成することを一般的に選択してきました。

## <Font color="red">The Use Cases for Automation</font>

自動化のためのユースケース

ここでは、自動化のためのユースケースを非網羅的にあげています

* ユーザアカウントの作成
* クラスタのturnup/turndown
* ソフトウェアまたはハードウェアのインストール準備と廃止
* 新しいソフトウェアバージョンのロールアウト
* ランタイム構成の変更、依存関係の変更

ユースケースは無限をあげることができる

### Google SRE’s Use Cases for Automation

Google SREの自動化のためのユースケース

グーグルでは、先ほどの使用例を多く持っています

infrastructure上を通過するデータの品質を管理することとは対照的に、Google SRE内での主要なアフィニティーはinfrastructureを実行することです

自動化のためのコンテキストは
システムのライフサイクルを管理するために自動化することで、
それらのデータ自体ではありません

？？この章よくわからなかった？？

### A Hierarchy of Automation Classes

自動化のクラスの階層

自動化の進化の経路について記述

1. 自動化しない
2. 外部で管理されている特別なシステムの自動化
3. 外部で管理されている汎用的な自動化
4. 内部で管理されている特別なシステムの自動化
5. 任意の自動化を必要としないシステム

？？？


## Automate Yourself Out of a Job: Automate ALL the Things!
